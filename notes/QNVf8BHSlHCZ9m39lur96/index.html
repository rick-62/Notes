<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><title>Batch</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal Knowledge Space"/><meta property="og:title" content="Batch"/><meta property="og:description" content="Personal Knowledge Space"/><meta property="og:url" content="https://rick-62.github.io/notes/QNVf8BHSlHCZ9m39lur96/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2/5/2022"/><meta property="article:modified_time" content="2/13/2022"/><link rel="canonical" href="https://rick-62.github.io/notes/QNVf8BHSlHCZ9m39lur96/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/_next/static/css/cc2307f6fd3a2fec.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cc2307f6fd3a2fec.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-709abf7ab5f510de.js" defer=""></script><script src="/_next/static/chunks/framework-bb5c596eafb42b22.js" defer=""></script><script src="/_next/static/chunks/main-c4b0e551a2150d17.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c259f160a0162632.js" defer=""></script><script src="/_next/static/chunks/826-e0e455fb469c158f.js" defer=""></script><script src="/_next/static/chunks/986-737e5da213076068.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bid%5D-00dd1421f3ce3a3e.js" defer=""></script><script src="/_next/static/x_d4yb4f_0V4SOPHOkEsf/_buildManifest.js" defer=""></script><script src="/_next/static/x_d4yb4f_0V4SOPHOkEsf/_ssgManifest.js" defer=""></script><script src="/_next/static/x_d4yb4f_0V4SOPHOkEsf/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><section class="ant-layout side-layout-main" style="max-width:1200px;display:initial"><main class="ant-layout-content main-content" role="main" style="padding:0 24px"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="batch"><a aria-hidden="true" class="anchor-heading" href="#batch"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Batch</h1>
<h1 id="deploy-kedro-to-batch-simple-version"><a aria-hidden="true" class="anchor-heading" href="#deploy-kedro-to-batch-simple-version"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Deploy kedro to batch (simple version)</h1>
<p>This deployment guide will outline the instructions for uploading a Kedro project to AWS Batch. This is for the main intention of allowing us to trigger running the project automatically using AWS Eventbridge, and output the results to an S3 bucket which can be accessed directly online.</p>
<p>Note: assumes AWS account has been setup and configured</p>
<h3 id="future-improvements"><a aria-hidden="true" class="anchor-heading" href="#future-improvements"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Future improvements</h3>
<ul>
<li>Use CDK/CLI to automate build of the AWS stack</li>
<li>Pass AWS parameters for better flexibility and separation of dependency</li>
<li>Run individual nodes on separate batch jobs</li>
<li>Improve public access policy for S3 bucket</li>
<li>Migrate to AWS serverless (step functions &#x26; lambda)</li>
</ul>
<h2 id="create-a-new-s3-bucket-in-aws"><a aria-hidden="true" class="anchor-heading" href="#create-a-new-s3-bucket-in-aws"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Create a new S3 bucket in AWS</h2>
<ol>
<li>Navigate to S3 Management Console in AWS</li>
<li>Click <strong>Create bucket</strong> </li>
<li>Name the bucket, adhering to <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html">bucket naming guidance</a></li>
<li>Ensure the region selected is correct for the project</li>
<li>Uncheck <strong>Block all public access</strong> so individual files can be exposed to the internet</li>
<li>Leave the remaining settings as default and click <strong>Create bucket</strong></li>
</ol>
<h2 id="create-a-new-kedro-config-folder-and-catalog-yaml"><a aria-hidden="true" class="anchor-heading" href="#create-a-new-kedro-config-folder-and-catalog-yaml"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Create a new Kedro config folder and catalog yaml</h2>
<ol>
<li>Navigate to project root directory</li>
<li>Create folder called <code>aws_batch</code> in <code>conf</code></li>
<li>Copy the <code>catalog.yml</code> from <code>base</code> and paste into <code>aws_batch</code></li>
<li>Within the copied <code>catalog.yml</code> edit the filepaths to point to the earlier created S3 bucket, replacing the data folder prefix with <code>s3://&#x3C;bucket-name>/</code></li>
</ol>
<h2 id="ensure-requirementstxt-is-up-to-date"><a aria-hidden="true" class="anchor-heading" href="#ensure-requirementstxt-is-up-to-date"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Ensure requirements.txt is up to date</h2>
<ol>
<li>Ensure <code>src/requirements.txt</code> contains all the required packages (and correct versions) to run the project locally</li>
<li>Can rebuild new virtual environment to test this is the case</li>
<li>Finally add <code>s3fs>=0.3.0,&#x3C;0.5</code> to requirements for reading/saving to S3 bucket</li>
</ol>
<h2 id="create-docker-container"><a aria-hidden="true" class="anchor-heading" href="#create-docker-container"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Create Docker container</h2>
<ol>
<li>Ensure Docker Daemon is running</li>
<li>Install <strong>kedro-docker</strong> using <code>pip install kedro-docker</code></li>
<li>run <code>kedro docker init</code> to create required files</li>
<li>run <code>kedro docker build </code> (note: repo name must be lowercase)</li>
</ol>
<h2 id="push-docker-image-to-repo-in-this-case-aws-ecr"><a aria-hidden="true" class="anchor-heading" href="#push-docker-image-to-repo-in-this-case-aws-ecr"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Push Docker image to repo (in this case AWS ECR)</h2>
<ol>
<li>Set up the repo in AWS ECR, giving the repo a sensible name <em>e.g. investing-batch</em></li>
<li>From command line on local machine run: <code>docker tag &#x3C;local-repo-name>:latest &#x3C;AWS-account-ID>.dkr.ecr.&#x3C;region>.amazonaws.com/&#x3C;aws-repo-name>:latest</code></li>
<li>Login to AWS on local machine by running: <code>aws ecr get-login-password --region &#x3C;region> | docker login --username AWS --password-stdin &#x3C;AWS-account-ID>.dkr.ecr.&#x3C;region>.amazonaws.com</code></li>
<li>Push the docker image to ECR: <code>docker push &#x3C;AWS-account-ID>.dkr.ecr.&#x3C;region>.amazonaws.com/&#x3C;aws-repo-name>:latest</code></li>
</ol>
<h2 id="setup-aws-batch"><a aria-hidden="true" class="anchor-heading" href="#setup-aws-batch"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Setup AWS Batch</h2>
<ol>
<li>Create IAM role so Batch can share information with ECR and S3 <a href="https://aws.amazon.com/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/">similar to this</a></li>
<li><code>Create job Definition</code> providing an appropriate name, assign the created IAM role, set command field to <code>kedro run --env aws_batch</code> and edit execution time etc accordingly, leaving most defaults as is</li>
<li><code>Create compute environment</code> providing an appropriate name and choosing Fargate </li>
<li><code>Create job queue</code> providing an appropriate name, the compute environment and setting the priority</li>
<li>Submit a new job to test it is working as intended</li>
</ol>
<h2 id="setup-scheduling"><a aria-hidden="true" class="anchor-heading" href="#setup-scheduling"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Setup scheduling</h2>
<ol>
<li>Navigate to AWS EventBridge</li>
<li>Click <code>Rules</code> > <code>Create rule</code> and provide an appropriate name</li>
<li>Select trigger type under <code>Define pattern</code> select either <code>Event</code> or <code>Schedule</code> driven</li>
<li>Select <code>Batch job queue</code> under <code>Target</code> and fill in ARNs for Batch components</li>
<li>Click <code>Create</code> to complete rule</li>
</ol>
<h2 id="accessing-the-output-data"><a aria-hidden="true" class="anchor-heading" href="#accessing-the-output-data"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Accessing the output data</h2>
<ol>
<li>Navigate to S3 bucket</li>
<li>Select data or output would like to access publicly</li>
<li>Select <code>Actions</code> > <code>Make public using ACL</code></li>
<li>Output data can now be accessed any time using S3 URL</li>
</ol>
<h2 id="references"><a aria-hidden="true" class="anchor-heading" href="#references"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>References</h2>
<p><a href="https://kedro.readthedocs.io/en/latest/10_deployment/07_aws_batch.html">https://kedro.readthedocs.io/en/latest/10_deployment/07_aws_batch.html</a>
<a href="https://aws.amazon.com/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/">https://aws.amazon.com/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/</a>
<a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html">https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html</a></p></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#deploy-kedro-to-batch-simple-version" title="Deploy kedro to batch (simple version)">Deploy kedro to batch (simple version)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#future-improvements" title="Future improvements">Future improvements</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#create-a-new-s3-bucket-in-aws" title="Create a new S3 bucket in AWS">Create a new S3 bucket in AWS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#create-a-new-kedro-config-folder-and-catalog-yaml" title="Create a new Kedro config folder and catalog yaml">Create a new Kedro config folder and catalog yaml</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ensure-requirementstxt-is-up-to-date" title="Ensure requirements.txt is up to date">Ensure requirements.txt is up to date</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#create-docker-container" title="Create Docker container">Create Docker container</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#push-docker-image-to-repo-in-this-case-aws-ecr" title="Push Docker image to repo (in this case AWS ECR)">Push Docker image to repo (in this case AWS ECR)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#setup-aws-batch" title="Setup AWS Batch">Setup AWS Batch</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#setup-scheduling" title="Setup scheduling">Setup scheduling</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#accessing-the-output-data" title="Accessing the output data">Accessing the output data</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#references" title="References">References</a></div></div></div></div></div></div></div></div></div></main><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></section></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"QNVf8BHSlHCZ9m39lur96","title":"Batch","desc":"","updated":1644787222841,"created":1644049006818,"custom":{},"fname":"cloud.aws.deploy.batch","type":"note","vault":{"fsPath":"vault"},"contentHash":"783fc38a55d401d5d0d0804fbbe4b3a5","links":[],"anchors":{"deploy-kedro-to-batch-simple-version":{"type":"header","text":"Deploy kedro to batch (simple version)","value":"deploy-kedro-to-batch-simple-version","line":8,"column":0,"depth":1},"future-improvements":{"type":"header","text":"Future improvements","value":"future-improvements","line":13,"column":0,"depth":3},"create-a-new-s3-bucket-in-aws":{"type":"header","text":"Create a new S3 bucket in AWS","value":"create-a-new-s3-bucket-in-aws","line":20,"column":0,"depth":2},"create-a-new-kedro-config-folder-and-catalog-yaml":{"type":"header","text":"Create a new Kedro config folder and catalog yaml","value":"create-a-new-kedro-config-folder-and-catalog-yaml","line":28,"column":0,"depth":2},"ensure-requirementstxt-is-up-to-date":{"type":"header","text":"Ensure requirements.txt is up to date","value":"ensure-requirementstxt-is-up-to-date","line":34,"column":0,"depth":2},"create-docker-container":{"type":"header","text":"Create Docker container","value":"create-docker-container","line":39,"column":0,"depth":2},"push-docker-image-to-repo-in-this-case-aws-ecr":{"type":"header","text":"Push Docker image to repo (in this case AWS ECR)","value":"push-docker-image-to-repo-in-this-case-aws-ecr","line":45,"column":0,"depth":2},"setup-aws-batch":{"type":"header","text":"Setup AWS Batch","value":"setup-aws-batch","line":51,"column":0,"depth":2},"setup-scheduling":{"type":"header","text":"Setup scheduling","value":"setup-scheduling","line":58,"column":0,"depth":2},"accessing-the-output-data":{"type":"header","text":"Accessing the output data","value":"accessing-the-output-data","line":65,"column":0,"depth":2},"references":{"type":"header","text":"References","value":"references","line":71,"column":0,"depth":2}},"children":[],"parent":"l54DdCSw9AE3pULxjQqmZ","data":{}},"body":"\u003ch1 id=\"batch\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#batch\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eBatch\u003c/h1\u003e\n\u003ch1 id=\"deploy-kedro-to-batch-simple-version\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#deploy-kedro-to-batch-simple-version\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eDeploy kedro to batch (simple version)\u003c/h1\u003e\n\u003cp\u003eThis deployment guide will outline the instructions for uploading a Kedro project to AWS Batch. This is for the main intention of allowing us to trigger running the project automatically using AWS Eventbridge, and output the results to an S3 bucket which can be accessed directly online.\u003c/p\u003e\n\u003cp\u003eNote: assumes AWS account has been setup and configured\u003c/p\u003e\n\u003ch3 id=\"future-improvements\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#future-improvements\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eFuture improvements\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eUse CDK/CLI to automate build of the AWS stack\u003c/li\u003e\n\u003cli\u003ePass AWS parameters for better flexibility and separation of dependency\u003c/li\u003e\n\u003cli\u003eRun individual nodes on separate batch jobs\u003c/li\u003e\n\u003cli\u003eImprove public access policy for S3 bucket\u003c/li\u003e\n\u003cli\u003eMigrate to AWS serverless (step functions \u0026#x26; lambda)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"create-a-new-s3-bucket-in-aws\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#create-a-new-s3-bucket-in-aws\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCreate a new S3 bucket in AWS\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eNavigate to S3 Management Console in AWS\u003c/li\u003e\n\u003cli\u003eClick \u003cstrong\u003eCreate bucket\u003c/strong\u003e \u003c/li\u003e\n\u003cli\u003eName the bucket, adhering to \u003ca href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html\"\u003ebucket naming guidance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eEnsure the region selected is correct for the project\u003c/li\u003e\n\u003cli\u003eUncheck \u003cstrong\u003eBlock all public access\u003c/strong\u003e so individual files can be exposed to the internet\u003c/li\u003e\n\u003cli\u003eLeave the remaining settings as default and click \u003cstrong\u003eCreate bucket\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"create-a-new-kedro-config-folder-and-catalog-yaml\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#create-a-new-kedro-config-folder-and-catalog-yaml\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCreate a new Kedro config folder and catalog yaml\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eNavigate to project root directory\u003c/li\u003e\n\u003cli\u003eCreate folder called \u003ccode\u003eaws_batch\u003c/code\u003e in \u003ccode\u003econf\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eCopy the \u003ccode\u003ecatalog.yml\u003c/code\u003e from \u003ccode\u003ebase\u003c/code\u003e and paste into \u003ccode\u003eaws_batch\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eWithin the copied \u003ccode\u003ecatalog.yml\u003c/code\u003e edit the filepaths to point to the earlier created S3 bucket, replacing the data folder prefix with \u003ccode\u003es3://\u0026#x3C;bucket-name\u003e/\u003c/code\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"ensure-requirementstxt-is-up-to-date\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#ensure-requirementstxt-is-up-to-date\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eEnsure requirements.txt is up to date\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eEnsure \u003ccode\u003esrc/requirements.txt\u003c/code\u003e contains all the required packages (and correct versions) to run the project locally\u003c/li\u003e\n\u003cli\u003eCan rebuild new virtual environment to test this is the case\u003c/li\u003e\n\u003cli\u003eFinally add \u003ccode\u003es3fs\u003e=0.3.0,\u0026#x3C;0.5\u003c/code\u003e to requirements for reading/saving to S3 bucket\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"create-docker-container\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#create-docker-container\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCreate Docker container\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eEnsure Docker Daemon is running\u003c/li\u003e\n\u003cli\u003eInstall \u003cstrong\u003ekedro-docker\u003c/strong\u003e using \u003ccode\u003epip install kedro-docker\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003erun \u003ccode\u003ekedro docker init\u003c/code\u003e to create required files\u003c/li\u003e\n\u003cli\u003erun \u003ccode\u003ekedro docker build \u003c/code\u003e (note: repo name must be lowercase)\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"push-docker-image-to-repo-in-this-case-aws-ecr\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#push-docker-image-to-repo-in-this-case-aws-ecr\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003ePush Docker image to repo (in this case AWS ECR)\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eSet up the repo in AWS ECR, giving the repo a sensible name \u003cem\u003ee.g. investing-batch\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003eFrom command line on local machine run: \u003ccode\u003edocker tag \u0026#x3C;local-repo-name\u003e:latest \u0026#x3C;AWS-account-ID\u003e.dkr.ecr.\u0026#x3C;region\u003e.amazonaws.com/\u0026#x3C;aws-repo-name\u003e:latest\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eLogin to AWS on local machine by running: \u003ccode\u003eaws ecr get-login-password --region \u0026#x3C;region\u003e | docker login --username AWS --password-stdin \u0026#x3C;AWS-account-ID\u003e.dkr.ecr.\u0026#x3C;region\u003e.amazonaws.com\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003ePush the docker image to ECR: \u003ccode\u003edocker push \u0026#x3C;AWS-account-ID\u003e.dkr.ecr.\u0026#x3C;region\u003e.amazonaws.com/\u0026#x3C;aws-repo-name\u003e:latest\u003c/code\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"setup-aws-batch\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#setup-aws-batch\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eSetup AWS Batch\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eCreate IAM role so Batch can share information with ECR and S3 \u003ca href=\"https://aws.amazon.com/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/\"\u003esimilar to this\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eCreate job Definition\u003c/code\u003e providing an appropriate name, assign the created IAM role, set command field to \u003ccode\u003ekedro run --env aws_batch\u003c/code\u003e and edit execution time etc accordingly, leaving most defaults as is\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eCreate compute environment\u003c/code\u003e providing an appropriate name and choosing Fargate \u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eCreate job queue\u003c/code\u003e providing an appropriate name, the compute environment and setting the priority\u003c/li\u003e\n\u003cli\u003eSubmit a new job to test it is working as intended\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"setup-scheduling\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#setup-scheduling\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eSetup scheduling\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eNavigate to AWS EventBridge\u003c/li\u003e\n\u003cli\u003eClick \u003ccode\u003eRules\u003c/code\u003e \u003e \u003ccode\u003eCreate rule\u003c/code\u003e and provide an appropriate name\u003c/li\u003e\n\u003cli\u003eSelect trigger type under \u003ccode\u003eDefine pattern\u003c/code\u003e select either \u003ccode\u003eEvent\u003c/code\u003e or \u003ccode\u003eSchedule\u003c/code\u003e driven\u003c/li\u003e\n\u003cli\u003eSelect \u003ccode\u003eBatch job queue\u003c/code\u003e under \u003ccode\u003eTarget\u003c/code\u003e and fill in ARNs for Batch components\u003c/li\u003e\n\u003cli\u003eClick \u003ccode\u003eCreate\u003c/code\u003e to complete rule\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"accessing-the-output-data\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#accessing-the-output-data\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eAccessing the output data\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eNavigate to S3 bucket\u003c/li\u003e\n\u003cli\u003eSelect data or output would like to access publicly\u003c/li\u003e\n\u003cli\u003eSelect \u003ccode\u003eActions\u003c/code\u003e \u003e \u003ccode\u003eMake public using ACL\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eOutput data can now be accessed any time using S3 URL\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"references\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#references\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eReferences\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://kedro.readthedocs.io/en/latest/10_deployment/07_aws_batch.html\"\u003ehttps://kedro.readthedocs.io/en/latest/10_deployment/07_aws_batch.html\u003c/a\u003e\n\u003ca href=\"https://aws.amazon.com/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/\"\u003ehttps://aws.amazon.com/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/\u003c/a\u003e\n\u003ca href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html\"\u003ehttps://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html\u003c/a\u003e\u003c/p\u003e","noteIndex":{"id":"wKnnZhcT81I2alc5HhXno","title":"My Notes","desc":"","updated":1646173420202,"created":1641216001965,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"23c39f5d43671e2637693fd87342c2be","links":[],"anchors":{"useful-dendron-resources":{"type":"header","text":"Useful Dendron resources","value":"useful-dendron-resources","line":17,"column":0,"depth":2}},"children":["7wtd2ak5s7jnkqjv8i5i3ps","sYfiAktveIvkILM3fU7yB","16imzpAsqMNTJWlocVcKd","cjBwhNONpuMscNbjewu8c","EsqRBfxiZHAMi1cWO1kJO","jHwcTQeSxj4MgEpLIn5ZM","85vKTbSj5SAHmePl0EQfI","lVEmg3KrF6EP6aqrVtEoL","BygRptOx3rKYLAUcZh6NB","HXj3jkv5vTwRzIk3Isx4E"],"parent":null,"data":{},"body":"\nI am using Dendron to store all of my notes. \n\nThis includes everything from courses \u0026 books, as well as general reference and useful information from videos \u0026 articles.\n\nGithub Actions is configured to republish the notes on each commit: \n\nhttps://rick-62.github.io/Notes/\n\n\n## Useful Dendron resources\n\nThis section contains useful links to related resources.\n\n- [Getting Started Guide](https://link.dendron.so/6b25)\n- [Discord](https://link.dendron.so/6b23)\n- [Home Page](https://wiki.dendron.so/)\n- [Github](https://link.dendron.so/6b24)\n- [Developer Docs](https://docs.dendron.so/)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"publishing":{"siteFaviconPath":"/Notes/favicon.ico","enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enablePrettyLinks":true,"assetsPrefix":"/Notes","siteUrl":"https://rick-62.github.io","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"enableTaskNotes":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"randomNote":{},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableHandlebarTemplates":true,"enableFullHierarchyNoteTitle":false,"enableSmartRefs":false,"dendronVersion":"0.105.0"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"useFMTitle":true,"useNoteTitleForLink":true,"mermaid":true,"useKatex":true,"site":{"copyAssets":true,"siteHierarchies":["root"],"siteRootDir":"docs","usePrettyRefs":true,"title":"Dendron","description":"Personal knowledge space","siteLastModified":true,"gh_edit_branch":"main","siteUrl":"localhost:3000","usePrettyLinks":true,"siteNotesDir":"notes","siteFaviconPath":"favicon.ico","gh_edit_link":true,"gh_edit_link_text":"Edit this page on GitHub","gh_root":"docs/","gh_edit_view_mode":"edit","writeStubs":true,"siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"QNVf8BHSlHCZ9m39lur96"},"buildId":"x_d4yb4f_0V4SOPHOkEsf","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>